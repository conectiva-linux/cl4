diff -u --recursive --new-file v2.2.5/linux/arch/alpha/lib/io.c linux/arch/alpha/lib/io.c
--- v2.2.5/linux/arch/alpha/lib/io.c	Wed Sep  9 14:51:04 1998
+++ linux/arch/alpha/lib/io.c	Thu Apr 15 05:42:31 1999
@@ -405,15 +405,16 @@
  * Copy data from "real" memory space to IO memory space.
  * This needs to be optimized.
  */
-void _memcpy_toio(unsigned long to, void * from, long count)
+void _memcpy_toio(unsigned long to, const void * from, long count)
 {
 	/* Optimize co-aligned transfers.  Everything else gets handled
 	   a byte at a time. */
+	/* FIXME -- align FROM.  */
 
 	if (count >= 8 && (to & 7) == ((long)from & 7)) {
 		count -= 8;
 		do {
-			writeq(*(u64 *)from, to);
+			writeq(*(const u64 *)from, to);
 			count -= 8;
 			to += 8;
 			from += 8;
@@ -424,7 +425,7 @@
 	if (count >= 4 && (to & 3) == ((long)from & 3)) {
 		count -= 4;
 		do {
-			writel(*(u32 *)from, to);
+			writel(*(const u32 *)from, to);
 			count -= 4;
 			to += 4;
 			from += 4;
@@ -435,7 +436,7 @@
 	if (count >= 2 && (to & 1) == ((long)from & 1)) {
 		count -= 2;
 		do {
-			writew(*(u16 *)from, to);
+			writew(*(const u16 *)from, to);
 			count -= 2;
 			to += 2;
 			from += 2;
@@ -444,7 +445,7 @@
 	}
 
 	while (count > 0) {
-		writeb(*(u8 *) from, to);
+		writeb(*(const u8 *) from, to);
 		count--;
 		to++;
 		from++;
diff -u --recursive --new-file v2.2.5/linux/include/asm-alpha/io.h linux/include/asm-alpha/io.h
--- v2.2.5/linux/include/asm-alpha/io.h	Wed Jan 13 15:00:43 1999
+++ linux/include/asm-alpha/io.h	Thu Apr 15 05:42:31 1999
@@ -287,7 +287,7 @@
  * String version of IO memory access ops:
  */
 extern void _memcpy_fromio(void *, unsigned long, long);
-extern void _memcpy_toio(unsigned long, void *, long);
+extern void _memcpy_toio(unsigned long, const void *, long);
 extern void _memset_c_io(unsigned long, unsigned long, long);
 
 #define memcpy_fromio(to,from,len) \
diff -u --recursive --new-file v2.2.5/linux/include/asm-alpha/semaphore-helper.h linux/include/asm-alpha/semaphore-helper.h
--- v2.2.5/linux/include/asm-alpha/semaphore-helper.h	Tue Mar 23 14:35:48 1999
+++ linux/include/asm-alpha/semaphore-helper.h	Thu Apr 15 05:42:32 1999
@@ -50,7 +50,7 @@
  *	0	go to sleep
  *	-EINTR	interrupted
  *
- * We must undo the sem->count down_interruptible increment
+ * We must undo the sem->count down_interruptible decrement
  * simultaneously and atomicly with the sem->waking adjustment,
  * otherwise we can race with wake_one_more.
  *
diff -u --recursive --new-file v2.2.5/linux/include/asm-alpha/semaphore.h linux/include/asm-alpha/semaphore.h
--- v2.2.5/linux/include/asm-alpha/semaphore.h	Tue Mar 23 14:35:48 1999
+++ linux/include/asm-alpha/semaphore.h	Fri Apr 16 08:22:49 1999
@@ -115,42 +115,46 @@
 
 extern inline int down_trylock(struct semaphore * sem)
 {
-	long ret, tmp, tmp2;
+	long ret, tmp, tmp2, sub;
 
 	/* "Equivalent" C.  Note that we have to do this all without
 	   (taken) branches in order to be a valid ll/sc sequence.
 
 	   do {
 	       tmp = ldq_l;
-	       ret = 0;
-	       tmp -= 1;
-	       if ((int)tmp < 0)		// count
-	           break;
-	       if ((long)tmp < 0)		// waking
-	           break;
-	       tmp += 0xffffffff00000000;
-	       ret = 1;
+	       sub = 0x0000000100000000;
+	       ret = ((int)tmp <= 0);		// count =< 0 ?
+	       if ((int)tmp >= 0) sub = 0;	// count >= 0 ?
+			// note that if count=0 subq overflows to the high
+			// longword (i.e waking)
+	       ret &= ((long)tmp < 0);		// waking < 0 ?
+	       sub += 1;
+	       if (ret) 
+			break;	
+	       tmp -= sub;
 	       tmp = stq_c = tmp;
 	   } while (tmp == 0);
 	*/
 
 	__asm__ __volatile__(
-		"1:	ldq_l	%1,%3\n"
-		"	lda	%0,0\n"
-		"	subl	%1,1,%2\n"
-		"	subq	%1,1,%1\n"
-		"	blt	%2,2f\n"
-		"	blt	%1,2f\n"
-		"	ldah	%1,-32768(%1)\n"
-		"	ldah	%1,-32768(%1)\n"
-		"	lda	%0,1\n"
-		"	stq_c	%1,%3\n"
+		"1:	ldq_l	%1,%4\n"
+		"	lda	%3,1\n"
+		"	addl	%1,0,%2\n"
+		"	sll	%3,32,%3\n"
+		"	cmple	%2,0,%0\n"
+		"	cmovge	%2,0,%3\n"
+		"	cmplt	%1,0,%2\n"
+		"	addq	%3,1,%3\n"
+		"	and	%0,%2,%0\n"
+		"	bne	%0,2f\n"
+		"	subq	%1,%3,%1\n"
+		"	stq_c	%1,%4\n"
 		"	beq	%1,3f\n"
-		"2:	mb\n"
+		"2:\n"
 		".section .text2,\"ax\"\n"
 		"3:	br	1b\n"
 		".previous"
-		: "=&r"(ret), "=&r"(tmp), "=&r"(tmp2)
+		: "=&r"(ret), "=&r"(tmp), "=&r"(tmp2), "=&r"(sub)
 		: "m"(*sem)
 		: "memory");
 
diff -u --recursive --new-file v2.2.5/linux/include/asm-alpha/uaccess.h linux/include/asm-alpha/uaccess.h
--- v2.2.5/linux/include/asm-alpha/uaccess.h	Wed Jun 24 22:54:10 1998
+++ linux/include/asm-alpha/uaccess.h	Thu Apr 15 05:42:31 1999
@@ -358,43 +358,55 @@
  * Complex access routines
  */
 
-#define __copy_to_user(to,from,n)   __copy_tofrom_user_nocheck((to),(from),(n))
-#define __copy_from_user(to,from,n) __copy_tofrom_user_nocheck((to),(from),(n))
-
-#define copy_to_user(to,from,n)   __copy_tofrom_user((to),(from),(n),__cu_to)
-#define copy_from_user(to,from,n) __copy_tofrom_user((to),(from),(n),__cu_from)
-
 extern void __copy_user(void);
 
-#define __copy_tofrom_user_nocheck(to,from,n)				\
-({									\
-	register void * __cu_to __asm__("$6") = (to);			\
-	register const void * __cu_from __asm__("$7") = (from);		\
-	register long __cu_len __asm__("$0") = (n);			\
-	__asm__ __volatile__(						\
-		"jsr $28,(%3),__copy_user"				\
-		: "=r" (__cu_len), "=r" (__cu_from), "=r" (__cu_to)	\
-		: "r" (__copy_user), "0" (__cu_len),			\
-		  "1" (__cu_from), "2" (__cu_to)			\
-		: "$1","$2","$3","$4","$5","$28","memory");		\
-	__cu_len;							\
-})
+extern inline long
+__copy_tofrom_user_nocheck(void *to, const void *from, long len)
+{
+	register void * __cu_to __asm__("$6") = to;
+	register const void * __cu_from __asm__("$7") = from;
+	register long __cu_len __asm__("$0") = len;
+
+	__asm__ __volatile__(
+		"jsr $28,__copy_user"
+		: "=r" (__cu_len), "=r" (__cu_from), "=r" (__cu_to)
+		: "0" (__cu_len), "1" (__cu_from), "2" (__cu_to)
+		: "$1","$2","$3","$4","$5","$27","$28","memory");
+
+	return __cu_len;
+}
+
+extern inline long
+__copy_tofrom_user(void *to, const void *from, long len, const void *validate)
+{
+	if (__access_ok((long)validate, len, get_fs())) {
+		register void * __cu_to __asm__("$6") = to;
+		register const void * __cu_from __asm__("$7") = from;
+		register long __cu_len __asm__("$0") = len;
+		__asm__ __volatile__(
+			"jsr $28,__copy_user"
+			: "=r" (__cu_len), "=r" (__cu_from), "=r" (__cu_to)
+			: "0" (__cu_len), "1" (__cu_from), "2" (__cu_to)
+			: "$1","$2","$3","$4","$5","$27","$28","memory");
+		len = __cu_len;
+	}
+	return len;
+}
 
-#define __copy_tofrom_user(to,from,n,v)					    \
-({									    \
-	register void * __cu_to __asm__("$6") = (to);			    \
-	register const void * __cu_from __asm__("$7") = (from);		    \
-	register long __cu_len __asm__("$0") = (n);			    \
-	if (__access_ok(((long)(v)),__cu_len,get_fs())) {		    \
-		__asm__ __volatile__(					    \
-			"jsr $28,(%3),__copy_user"			    \
-			: "=r" (__cu_len), "=r" (__cu_from), "=r" (__cu_to) \
-			: "r" (__copy_user), "0" (__cu_len),		    \
-			  "1" (__cu_from), "2" (__cu_to)   		    \
-			: "$1","$2","$3","$4","$5","$28","memory");	    \
-	}								    \
-	__cu_len;							    \
-})
+#define __copy_to_user(to,from,n)   __copy_tofrom_user_nocheck((to),(from),(n))
+#define __copy_from_user(to,from,n) __copy_tofrom_user_nocheck((to),(from),(n))
+
+extern inline long
+copy_to_user(void *to, const void *from, long n)
+{
+	return __copy_tofrom_user(to, from, n, to);
+}
+
+extern inline long
+copy_from_user(void *to, const void *from, long n)
+{
+	return __copy_tofrom_user(to, from, n, from);
+}
 
 #define copy_to_user_ret(to,from,n,retval) ({ \
 if (copy_to_user(to,from,n)) \
@@ -408,46 +420,48 @@
 
 extern void __do_clear_user(void);
 
-#define __clear_user(to,n)						\
-({									\
-	register void * __cl_to __asm__("$6") = (to);			\
-	register long __cl_len __asm__("$0") = (n);			\
-	__asm__ __volatile__(						\
-		"jsr $28,(%2),__do_clear_user"				\
-		: "=r"(__cl_len), "=r"(__cl_to)				\
-		: "r"(__do_clear_user), "0"(__cl_len), "1"(__cl_to)	\
-		: "$1","$2","$3","$4","$5","$28","memory");		\
-	__cl_len;							\
-})
-
-#define clear_user(to,n)						\
-({									\
-	register void * __cl_to __asm__("$6") = (to);			\
-	register long __cl_len __asm__("$0") = (n);			\
-	if (__access_ok(((long)__cl_to),__cl_len,get_fs())) {		\
-		__asm__ __volatile__(					\
-			"jsr $28,(%2),__do_clear_user"			\
-			: "=r"(__cl_len), "=r"(__cl_to)			\
-			: "r"(__do_clear_user), "0"(__cl_len), "1"(__cl_to)\
-			: "$1","$2","$3","$4","$5","$28","memory");	\
-	}								\
-	__cl_len;							\
-})
+extern inline long
+__clear_user(void *to, long len)
+{
+	register void * __cl_to __asm__("$6") = to;
+	register long __cl_len __asm__("$0") = len;
+	__asm__ __volatile__(
+		"jsr $28,__do_clear_user"
+		: "=r"(__cl_len), "=r"(__cl_to)
+		: "0"(__cl_len), "1"(__cl_to)
+		: "$1","$2","$3","$4","$5","$27","$28","memory");
+	return __cl_len;
+}
+
+extern inline long
+clear_user(void *to, long len)
+{
+	if (__access_ok((long)to, len, get_fs())) {
+		register void * __cl_to __asm__("$6") = to;
+		register long __cl_len __asm__("$0") = len;
+		__asm__ __volatile__(
+			"jsr $28,__do_clear_user"
+			: "=r"(__cl_len), "=r"(__cl_to)
+			: "0"(__cl_len), "1"(__cl_to)
+			: "$1","$2","$3","$4","$5","$27","$28","memory");
+		len = __cl_len;
+	}
+	return len;
+}
 
 /* Returns: -EFAULT if exception before terminator, N if the entire
    buffer filled, else strlen.  */
 
 extern long __strncpy_from_user(char *__to, const char *__from, long __to_len);
 
-#define strncpy_from_user(to,from,n)					   \
-({									   \
-	char * __sfu_to = (to);						   \
-	const char * __sfu_from = (from);				   \
-	long __sfu_ret = -EFAULT;			      		   \
-	if (__access_ok(((long)__sfu_from),0,get_fs()))			   \
-		__sfu_ret = __strncpy_from_user(__sfu_to,__sfu_from,(n));  \
-	__sfu_ret;							   \
-})
+extern inline long
+strncpy_from_user(char *to, const char *from, long n)
+{
+	long ret = -EFAULT;
+	if (__access_ok((long)from, 0, get_fs()))
+		ret = __strncpy_from_user(to, from, n);
+	return ret;
+}
 
 /* Returns: 0 if bad, string length+1 (memory size) of string if ok */
 extern long __strlen_user(const char *);
